# -*- coding: utf-8 -*-
"""ModelDegradationSimulator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14DgyG9rTv89568IjVwMoY3U32Ns3Gux8
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import seaborn as sns
plt.style.use('seaborn-v0_8')

class ModelDegradationSimulator:
    def __init__(self, initial_data_size=1000, noise_level=0.1):
        self.initial_data_size = initial_data_size
        self.noise_level = noise_level
        self.generations = []
        self.metrics_history = {
            'mse': [],
            'r2': [],
            'data_variance': [],
            'data_mean': [],
            'prediction_std': []
        }

    def generate_original_data(self):
        """Gera dados originais 'reais' para simular um dataset inicial"""
        np.random.seed(42)
        X = np.random.uniform(-5, 5, (self.initial_data_size, 3))
        # Função não-linear complexa para simular dados reais
        y = (2 * X[:, 0]**2 +
             np.sin(X[:, 1] * 2) +
             X[:, 2] * X[:, 0] +
             np.random.normal(0, self.noise_level, X.shape[0]))
        return X, y

    def train_model(self, X, y):
        """Treina um modelo nos dados fornecidos"""
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        model.fit(X_scaled, y)
        return model, scaler

    def generate_synthetic_data(self, model, scaler, size):
        """Gera dados sintéticos usando o modelo treinado"""
        # Gera novos pontos X de forma similar aos originais
        X_new = np.random.uniform(-5, 5, (size, 3))
        X_new_scaled = scaler.transform(X_new)

        # Usa o modelo para prever y, adicionando algum ruído
        y_pred = model.predict(X_new_scaled)

        # Adiciona ruído baseado na incerteza do modelo
        prediction_std = np.std(y_pred)
        noise = np.random.normal(0, prediction_std * 0.1, size)
        y_synthetic = y_pred + noise

        return X_new, y_synthetic

    def evaluate_model(self, model, scaler, X_test, y_test):
        """Avalia o modelo em dados de teste"""
        X_test_scaled = scaler.transform(X_test)
        y_pred = model.predict(X_test_scaled)

        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        return mse, r2, y_pred

    def simulate_degradation(self, num_generations=10):
        """Simula a degradação ao longo de múltiplas gerações"""
        print("Iniciando simulação de degradação de modelo...")

        # Dados originais (geração 0)
        X_original, y_original = self.generate_original_data()
        X_test, y_test = self.generate_original_data()  # Conjunto de teste fixo

        # Primeira geração: treina no dataset original
        current_X, current_y = X_original.copy(), y_original.copy()

        for generation in range(num_generations):
            print(f"Processando geração {generation}...")

            # Treina modelo na geração atual
            model, scaler = self.train_model(current_X, current_y)

            # Avalia no conjunto de teste fixo
            mse, r2, y_pred = self.evaluate_model(model, scaler, X_test, y_test)

            # Coleta métricas
            self.metrics_history['mse'].append(mse)
            self.metrics_history['r2'].append(r2)
            self.metrics_history['data_variance'].append(np.var(current_y))
            self.metrics_history['data_mean'].append(np.mean(current_y))
            self.metrics_history['prediction_std'].append(np.std(y_pred))

            # Armazena dados da geração
            self.generations.append({
                'X': current_X.copy(),
                'y': current_y.copy(),
                'model': model,
                'scaler': scaler
            })

            # Gera dados sintéticos para próxima geração
            if generation < num_generations - 1:
                current_X, current_y = self.generate_synthetic_data(
                    model, scaler, self.initial_data_size
                )

        print("Simulação concluída!")

    def plot_degradation_metrics(self):
        """Visualiza as métricas de degradação"""
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle('Degradação do Modelo ao Longo das Gerações', fontsize=16)

        generations = range(len(self.metrics_history['mse']))

        # MSE
        axes[0, 0].plot(generations, self.metrics_history['mse'], 'o-', color='red')
        axes[0, 0].set_title('Erro Quadrático Médio (MSE)')
        axes[0, 0].set_xlabel('Geração')
        axes[0, 0].set_ylabel('MSE')
        axes[0, 0].grid(True, alpha=0.3)

        # R²
        axes[0, 1].plot(generations, self.metrics_history['r2'], 'o-', color='blue')
        axes[0, 1].set_title('Coeficiente de Determinação (R²)')
        axes[0, 1].set_xlabel('Geração')
        axes[0, 1].set_ylabel('R²')
        axes[0, 1].grid(True, alpha=0.3)

        # Variância dos dados
        axes[0, 2].plot(generations, self.metrics_history['data_variance'], 'o-', color='green')
        axes[0, 2].set_title('Variância dos Dados de Treinamento')
        axes[0, 2].set_xlabel('Geração')
        axes[0, 2].set_ylabel('Variância')
        axes[0, 2].grid(True, alpha=0.3)

        # Média dos dados
        axes[1, 0].plot(generations, self.metrics_history['data_mean'], 'o-', color='orange')
        axes[1, 0].set_title('Média dos Dados de Treinamento')
        axes[1, 0].set_xlabel('Geração')
        axes[1, 0].set_ylabel('Média')
        axes[1, 0].grid(True, alpha=0.3)

        # Desvio padrão das predições
        axes[1, 1].plot(generations, self.metrics_history['prediction_std'], 'o-', color='purple')
        axes[1, 1].set_title('Desvio Padrão das Predições')
        axes[1, 1].set_xlabel('Geração')
        axes[1, 1].set_ylabel('Std das Predições')
        axes[1, 1].grid(True, alpha=0.3)

        # Comparação MSE vs R²
        ax2 = axes[1, 2].twinx()
        line1 = axes[1, 2].plot(generations, self.metrics_history['mse'], 'o-', color='red', label='MSE')
        line2 = ax2.plot(generations, self.metrics_history['r2'], 's-', color='blue', label='R²')
        axes[1, 2].set_xlabel('Geração')
        axes[1, 2].set_ylabel('MSE', color='red')
        ax2.set_ylabel('R²', color='blue')
        axes[1, 2].set_title('MSE vs R² ao Longo das Gerações')

        # Legenda combinada
        lines = line1 + line2
        labels = [l.get_label() for l in lines]
        axes[1, 2].legend(lines, labels, loc='center right')

        plt.tight_layout()
        plt.show()

    def plot_data_distribution_evolution(self):
        """Mostra como a distribuição dos dados muda ao longo das gerações"""
        fig, axes = plt.subplots(2, 5, figsize=(20, 8))
        fig.suptitle('Evolução da Distribuição dos Dados Alvo (y)', fontsize=16)

        generations_to_show = [0, 1, 2, 4, 6, 8, -1]  # Últimas gerações

        for i, gen_idx in enumerate(generations_to_show[:10]):
            row = i // 5
            col = i % 5

            if gen_idx == -1:
                gen_idx = len(self.generations) - 1

            if gen_idx < len(self.generations):
                y_data = self.generations[gen_idx]['y']
                axes[row, col].hist(y_data, bins=30, alpha=0.7, density=True)
                axes[row, col].set_title(f'Geração {gen_idx}')
                axes[row, col].set_ylabel('Densidade' if col == 0 else '')
                axes[row, col].grid(True, alpha=0.3)

        # Remove subplots vazios
        for i in range(len(generations_to_show), 10):
            row = i // 5
            col = i % 5
            fig.delaxes(axes[row, col])

        plt.tight_layout()
        plt.show()

    def print_degradation_summary(self):
        """Imprime um resumo da degradação observada"""
        print("\n" + "="*60)
        print("RESUMO DA DEGRADAÇÃO DO MODELO")
        print("="*60)

        initial_mse = self.metrics_history['mse'][0]
        final_mse = self.metrics_history['mse'][-1]
        initial_r2 = self.metrics_history['r2'][0]
        final_r2 = self.metrics_history['r2'][-1]

        print(f"Gerações simuladas: {len(self.metrics_history['mse'])}")
        print(f"\nMSE:")
        print(f"  Inicial: {initial_mse:.4f}")
        print(f"  Final: {final_mse:.4f}")
        print(f"  Degradação: {((final_mse - initial_mse) / initial_mse * 100):+.2f}%")

        print(f"\nR²:")
        print(f"  Inicial: {initial_r2:.4f}")
        print(f"  Final: {final_r2:.4f}")
        print(f"  Degradação: {((final_r2 - initial_r2) / abs(initial_r2) * 100):+.2f}%")

        print(f"\nVariância dos dados:")
        print(f"  Inicial: {self.metrics_history['data_variance'][0]:.4f}")
        print(f"  Final: {self.metrics_history['data_variance'][-1]:.4f}")

        print("\nObservações:")
        print("• MSE crescente indica piora na capacidade preditiva")
        print("• R² decrescente confirma degradação do modelo")
        print("• Mudanças na variância mostram alteração na distribuição dos dados")
        print("• Este fenômeno é conhecido como 'Model Collapse' ou 'Degeneração de Modelo'")

# Executar a simulação
if __name__ == "__main__":
    # Configurar simulação
    simulator = ModelDegradationSimulator(initial_data_size=1000, noise_level=0.1)

    # Executar simulação
    simulator.simulate_degradation(num_generations=100)

    # Visualizar resultados
    simulator.plot_degradation_metrics()
    simulator.plot_data_distribution_evolution()

    # Imprimir resumo
    simulator.print_degradation_summary()